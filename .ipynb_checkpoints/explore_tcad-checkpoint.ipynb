{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkZzKXgRX3yA"
   },
   "source": [
    "# TCAD file exploration\n",
    "\n",
    "We have received files from a client.  They are ....\n",
    "\n",
    "# Shorten files for browsing\n",
    "\n",
    "To shorten the files for browsing we can run a short shell script. This opens the zip that was received, and truncates each file at 100 lines long.\n",
    "\n",
    "```{bash, eval=F}\n",
    "# rm -rf shortened_appraisal_files\n",
    "unzip original_data/Appraisal_Roll_History_1990.zip -d shortened_appraisal_files\n",
    "find shortened_appraisal_files -name \"*.TXT\" -exec sed -i.full 100q {} \\;\n",
    "find shortened_appraisal_files -name \"*.TXT.full\" -exec rm {} \\;\n",
    "zip -r shortened_appraisal_files.zip shortened_appraisal_files\n",
    "```\n",
    "\n",
    "We can now attempt to load a shortened file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "OaixnN58XrvA",
    "outputId": "1b69c0da-42de-43b5-f72a-4487eb843d4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0000000003</th>\n",
       "      <th>0000</th>\n",
       "      <th>1990</th>\n",
       "      <th>02</th>\n",
       "      <th>0.56950</th>\n",
       "      <th>CI</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>275</th>\n",
       "      <th>0</th>\n",
       "      <th>2923</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>4098.00</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.00.1</th>\n",
       "      <th>12.23</th>\n",
       "      <th>11.11</th>\n",
       "      <th>23.34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>2923</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4098.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>CR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>2923</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4098.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>8</td>\n",
       "      <td>1.6410</td>\n",
       "      <td>SD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>2923</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4098.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.24</td>\n",
       "      <td>17.01</td>\n",
       "      <td>67.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2660</td>\n",
       "      <td>SD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25500</td>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>836.55</td>\n",
       "      <td>150.93</td>\n",
       "      <td>987.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>CI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25500</td>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.75</td>\n",
       "      <td>211.46</td>\n",
       "      <td>444.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0000000003  0000  1990  02  0.56950  CI  Unnamed: 6    275  0   2923  ...  \\\n",
       "0           3     0  1990   3   0.4090  CO         NaN    275  0   2923  ...   \n",
       "1           3     0  1990   4   0.0001  CR         NaN    275  0   2923  ...   \n",
       "2           3     0  1990   8   1.6410  SD         NaN    275  0   2923  ...   \n",
       "3           7     0  1990   1   1.2660  SD         NaN  25500  0  35000  ...   \n",
       "4           7     0  1990   2   0.5695  CI         NaN  25500  0  35000  ...   \n",
       "\n",
       "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  4098.00  0.00  0.00.1  \\\n",
       "0          NaN          NaN          NaN          NaN   4098.0   0.0     0.0   \n",
       "1          NaN          NaN          NaN          NaN   4098.0   0.0     0.0   \n",
       "2          NaN          NaN            Y          NaN   4098.0   0.0     0.0   \n",
       "3          NaN          NaN            Y          NaN  78000.0   0.0     0.0   \n",
       "4          NaN          NaN          NaN          NaN  78000.0   0.0     0.0   \n",
       "\n",
       "    12.23   11.11   23.34  \n",
       "0   16.76    0.00   16.76  \n",
       "1    0.00    0.00    0.00  \n",
       "2   50.24   17.01   67.25  \n",
       "3  836.55  150.93  987.48  \n",
       "4  232.75  211.46  444.21  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"shortened_appraisal_files/Appraisal_Roll_History_1990_A/TCBC_SUM_1990_JURIS.TXT\", sep = \"|\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGoM5byZX_nX"
   },
   "source": [
    "Challenge now is to use the *.TDF files to create tables.  I can think of two approaches.\n",
    "\n",
    "1. The TDF files are SQL, so if those are fed to duckdb they should be able to create tables into which the TXT pipe-separated CSV files can be read.  There may be issues with the datatypes not matching (which would require mapping the current datatype definitions to duckdb datatypes by changing the words used to give the datatype to the columns).\n",
    "\n",
    "2. Take the column names out of the TDF files and add them as the column names while reading the relevant CSV files into duckdb.  This would use duckdb's auto understanding of the column datatypes (so it would run, but it might guess wrongly and truncate or change data).\n",
    "\n",
    "I think we should explore step 1 first.\n",
    "\n",
    "## Creating tables using the TDF files\n",
    "\n",
    "We have TDF files scattered through the \\_A and \\_B folders.  I have created a schema (a namespace) for the files from \\_A called \"folder_A\" and \"folder_B\". So there are tables named the same thing in each of the schemas.  You can reference the tables as folder_A.TCBC_SUM_1990_JURIS and folder_B.TCBC_SUM_1990_JURIS \n",
    "\n",
    "We can use python to read each TDF file separately, create the table and then try to load the matching TXT file.  A little guidance on how to process a directory structure of files using Path and glob here:\n",
    "http://howisonlab.github.io/datawrangling/faq.html#get-data-from-filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CGkcMOxEX9_u"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect('duckdb-file.db') #  string to persist to disk\n",
    "cursor = con.cursor()\n",
    "\n",
    "# file_directory = 'shortened_appraisal_files/'\n",
    "file_directory = 'data/'\n",
    "# limit_to_file = 'TCBC_SUM_1990_JURIS'\n",
    "limit_to_file = '*' # all files\n",
    "\n",
    "# create schemas\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS folder_A_TCBC;\")\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS folder_A_TXBC;\")\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS folder_B_TCBC;\")\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS folder_B_TXBC;\")\n",
    "# delete schemas that created previously\n",
    "# cursor.execute(\"DROP SCHEMA IF EXISTS folder_A CASCADE\")\n",
    "# cursor.execute(\"DROP SCHEMA IF EXISTS folder_B CASCADE\")\n",
    "\n",
    "for filename in Path(file_directory).rglob(limit_to_file + '.TDF'):\n",
    "    print(filename.parts)\n",
    "    if \"_A\" in filename.parts[1] and \"TCBC_\" in filename.parts[2]:\n",
    "        schema = \"folder_A_TCBC\"\n",
    "    elif \"_A\" in filename.parts[1] and \"TXBC_\" in filename.parts[2]:\n",
    "        schema = \"folder_A_TXBC\"\n",
    "    elif \"_B\" in filename.parts[1] and \"TCBC_\" in filename.parts[2]:\n",
    "        schema = \"folder_B_TCBC\"\n",
    "    elif \"_B\" in filename.parts[1] and \"TXBC_\" in filename.parts[2]:\n",
    "        schema = \"folder_B_TXBC\"\n",
    "    \n",
    "    table_name = schema + \".\" + Path(filename).stem # e.g., A_TCBC_SUM_1990_JURIS\n",
    "\n",
    "    # read .TDF file into string\n",
    "    create_table_sql = Path(filename).read_text()\n",
    "    # Need to alter table name to read in both _A and _B files\n",
    "    create_table_sql = create_table_sql.replace(Path(filename).stem, table_name)\n",
    "    \n",
    "    # Here we have the table creation code in a string, so we can\n",
    "    # swap datatypes out.\n",
    "    # tried SMALLDATETIME --> DATETIME but was still giving errors\n",
    "    # will need to fix this later.\n",
    "    create_table_sql = create_table_sql.replace(\"SMALLDATETIME\", \"TEXT\")\n",
    "    \n",
    "\n",
    "    # execute that SQL with duckdb, this should create the table\n",
    "#     already created table so no need to run\n",
    "#     cursor.execute(create_table_sql) \n",
    "\n",
    "    # copy CSV into duckdb. CSV is the matching .TXT\n",
    "    path_to_csvpipefile = Path(filename).with_suffix(\".TXT\")\n",
    "    # duckdb copy documentation: https://duckdb.org/docs/sql/statements/copy.html\n",
    "    query = f\"COPY {table_name} FROM '{path_to_csvpipefile}' ( DELIMITER '|')\"\n",
    "    cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZM4OPEyJYGt5"
   },
   "outputs": [],
   "source": [
    "#set up sql for dbdocs\n",
    "for filename in Path(file_directory).rglob(limit_to_file + '.TDF'):\n",
    "\n",
    "    # SQL table code with commas\n",
    "    dbdocs_create_table = create_table_sql\n",
    "\n",
    "    # Remove commas before closing parentheses using regular expressions\n",
    "    dbdocs_create_table = dbdocs_create_table.replace(\"),\", \")\")\n",
    "\n",
    "    # Print the updated SQL table code\n",
    "    print(dbdocs_create_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "stBcf3j2YLn4"
   },
   "outputs": [],
   "source": [
    "# setup from https://duckdb.org/docs/guides/python/jupyter.html\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "# No need to import duckdb_engine\n",
    "#  jupysql will auto-detect the driver needed based on the connection string!\n",
    "\n",
    "# Import jupysql Jupyter extension to create SQL cells\n",
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ba4ZPL06YNWx"
   },
   "outputs": [],
   "source": [
    "%sql duckdb:///duckdb-file.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_gypNBKuYPlR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SHOW TABLES -- no schema name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGI5CXL3YE9V"
   },
   "source": [
    "Hey, duckdb implements all the same information schema names as postgres, so one can use the same queries to find the tables with their schaema names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GT1dWHiIYduW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT schemaname AS schema_name, tablename AS table_name\n",
    "FROM pg_catalog.pg_tables\n",
    "WHERE schemaname != 'pg_catalog'\n",
    "AND schemaname != 'information_schema'\n",
    "ORDER BY schemaname, tablename ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLpnEkVcZ4V3"
   },
   "source": [
    "Suppose total of 134933 rows, rows are adding up everytime rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mPFp7_qxZ7Js"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.CatalogException) Catalog Error: Table with name TCBC_SUM_1990_JURIS does not exist!\n",
      "Did you mean \"temp.information_schema.columns\"?\n",
      "LINE 1: SELECT * FROM folder_A_TCBC.TCBC_SUM_1990_JURIS;\n",
      "                      ^\n",
      "[SQL: SELECT * FROM folder_A_TCBC.TCBC_SUM_1990_JURIS;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM folder_A_TCBC.TCBC_SUM_1990_JURIS;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCRKDFCsZ_uU"
   },
   "source": [
    "Since the data duplicates, then use distinct feature to get correct data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4FcRzOpraBs1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.CatalogException) Catalog Error: Table with name TCBC_SUM_1990_JURIS does not exist!\n",
      "Did you mean \"temp.information_schema.columns\"?\n",
      "LINE 1: SELECT DISTINCT * FROM folder_A_TCBC.TCBC_SUM_1990_JURIS;\n",
      "                               ^\n",
      "[SQL: SELECT DISTINCT * FROM folder_A_TCBC.TCBC_SUM_1990_JURIS;]\n",
      "(Background on this error at: https://sqlalche.me/e/14/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT * FROM folder_A_TCBC.TCBC_SUM_1990_JURIS;"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPsK1xq8p8tJXnz1EPTIXvC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
